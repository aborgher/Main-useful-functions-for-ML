{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Small-example-found-around-in-the-web\" data-toc-modified-id=\"Small-example-found-around-in-the-web-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Small example found around in the web</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running the kernel jupyter-scala installed at https://github.com/jupyter-scala/jupyter-scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-10T18:27:23.477104Z",
     "start_time": "2017-09-10T16:27:19.928Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/slf4j-nop-1.7.21.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/slf4j-nop-1.7.21.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/slf4j-nop-1.7.21.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/slf4j-nop-1.7.21.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-parent/1.7.21/slf4j-parent-1.7.21.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-parent/1.7.21/slf4j-parent-1.7.21.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-parent/1.7.21/slf4j-parent-1.7.21.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-parent/1.7.21/slf4j-parent-1.7.21.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-parent/1.7.21/\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-parent/1.7.21/\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/slf4j-nop-1.7.21.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/slf4j-nop-1.7.21.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/slf4j-nop-1.7.21.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.21/slf4j-nop-1.7.21.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/2.1.0/spark-sql_2.12-2.1.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/2.1.0/spark-sql_2.12-2.1.0.pom.sha1\n",
      "Downloading https://oss.sonatype.org/content/repositories/releases/org/apache/spark/spark-sql_2.12/2.1.0/spark-sql_2.12-2.1.0.pom\n",
      "Downloading https://oss.sonatype.org/content/repositories/releases/org/apache/spark/spark-sql_2.12/2.1.0/spark-sql_2.12-2.1.0.pom.sha1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mammonite.runtime.tools.DependencyThing$IvyResolutionException: failed to resolve dependencies:",
      "  Dependency(org.apache.spark:spark-sql_2.12,2.1.0,compile,Set((org.slf4j,slf4j-log4j12)),Attributes(,),false,true): not found: /home/ale/.ivy2/local/org.apache.spark/spark-sql_2.12/2.1.0/ivys/ivy.xml, not found: https://repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/2.1.0/spark-sql_2.12-2.1.0.pom, not found: https://oss.sonatype.org/content/repositories/releases/org/apache/spark/spark-sql_2.12/2.1.0/spark-sql_2.12-2.1.0.pom\u001b[39m",
      "  ammonite.runtime.tools.DependencyThing.resolveArtifact(\u001b[32mDependencyThing.scala\u001b[39m:\u001b[32m93\u001b[39m)",
      "  ammonite.interp.Interpreter.loadIvy(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m665\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy.liftedTree1$1(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m182\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy.$anonfun$resolve$2(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m182\u001b[39m)",
      "  ammonite.util.Res$Success.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy.resolve(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m179\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy.$anonfun$handle$7(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m191\u001b[39m)",
      "  ammonite.util.Res$.$anonfun$map$1(\u001b[32mRes.scala\u001b[39m:\u001b[32m34\u001b[39m)",
      "  scala.collection.LinearSeqOptimized.foldLeft(\u001b[32mLinearSeqOptimized.scala\u001b[39m:\u001b[32m122\u001b[39m)",
      "  scala.collection.LinearSeqOptimized.foldLeft$(\u001b[32mLinearSeqOptimized.scala\u001b[39m:\u001b[32m118\u001b[39m)",
      "  scala.collection.immutable.List.foldLeft(\u001b[32mList.scala\u001b[39m:\u001b[32m86\u001b[39m)",
      "  ammonite.util.Res$.map(\u001b[32mRes.scala\u001b[39m:\u001b[32m31\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy.$anonfun$handle$6(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m191\u001b[39m)",
      "  ammonite.util.Res$Success.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy.handle(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m190\u001b[39m)",
      "  ammonite.interp.Interpreter.$anonfun$resolveSingleImportHook$5(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m181\u001b[39m)",
      "  ammonite.util.Res$Success.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  ammonite.interp.Interpreter.resolveSingleImportHook(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m180\u001b[39m)",
      "  ammonite.interp.Interpreter.$anonfun$resolveImportHooks$3(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m229\u001b[39m)",
      "  ammonite.util.Res$.$anonfun$map$1(\u001b[32mRes.scala\u001b[39m:\u001b[32m34\u001b[39m)",
      "  scala.collection.IndexedSeqOptimized.foldLeft(\u001b[32mIndexedSeqOptimized.scala\u001b[39m:\u001b[32m56\u001b[39m)",
      "  scala.collection.IndexedSeqOptimized.foldLeft$(\u001b[32mIndexedSeqOptimized.scala\u001b[39m:\u001b[32m64\u001b[39m)",
      "  scala.collection.mutable.ArrayBuffer.foldLeft(\u001b[32mArrayBuffer.scala\u001b[39m:\u001b[32m48\u001b[39m)",
      "  ammonite.util.Res$.map(\u001b[32mRes.scala\u001b[39m:\u001b[32m31\u001b[39m)",
      "  ammonite.interp.Interpreter.resolveImportHooks(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m229\u001b[39m)",
      "  ammonite.interp.Interpreter.$anonfun$processLine$3(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m245\u001b[39m)",
      "  ammonite.util.Catching.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m109\u001b[39m)",
      "  ammonite.interp.Interpreter.processLine(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m239\u001b[39m)",
      "  jupyter.scala.Interp.$anonfun$interpret$8(\u001b[32mInterp.scala\u001b[39m:\u001b[32m147\u001b[39m)",
      "  jupyter.scala.Capture$.$anonfun$withErr$1(\u001b[32mCapture.scala\u001b[39m:\u001b[32m46\u001b[39m)",
      "  scala.util.DynamicVariable.withValue(\u001b[32mDynamicVariable.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  scala.Console$.withErr(\u001b[32mConsole.scala\u001b[39m:\u001b[32m192\u001b[39m)",
      "  jupyter.scala.Capture$.withErr(\u001b[32mCapture.scala\u001b[39m:\u001b[32m42\u001b[39m)",
      "  jupyter.scala.Capture$.$anonfun$withOutAndErr$3(\u001b[32mCapture.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  jupyter.scala.Capture$.$anonfun$withOut$1(\u001b[32mCapture.scala\u001b[39m:\u001b[32m37\u001b[39m)",
      "  scala.util.DynamicVariable.withValue(\u001b[32mDynamicVariable.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  scala.Console$.withOut(\u001b[32mConsole.scala\u001b[39m:\u001b[32m163\u001b[39m)",
      "  jupyter.scala.Capture$.withOut(\u001b[32mCapture.scala\u001b[39m:\u001b[32m33\u001b[39m)",
      "  jupyter.scala.Capture$.withOutAndErr(\u001b[32mCapture.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  jupyter.scala.Capture$.apply(\u001b[32mCapture.scala\u001b[39m:\u001b[32m106\u001b[39m)",
      "  jupyter.scala.Interp.capturingOutput(\u001b[32mInterp.scala\u001b[39m:\u001b[32m104\u001b[39m)",
      "  jupyter.scala.Interp.$anonfun$interpret$7(\u001b[32mInterp.scala\u001b[39m:\u001b[32m146\u001b[39m)",
      "  jupyter.scala.Scoped.$anonfun$flatMap$1(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m45\u001b[39m)",
      "  jupyter.scala.Signaller.apply(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m30\u001b[39m)",
      "  jupyter.scala.Scoped.flatMap(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m45\u001b[39m)",
      "  jupyter.scala.Scoped.flatMap$(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m45\u001b[39m)",
      "  jupyter.scala.Signaller.flatMap(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m12\u001b[39m)",
      "  jupyter.scala.Interp.$anonfun$interpret$5(\u001b[32mInterp.scala\u001b[39m:\u001b[32m142\u001b[39m)",
      "  ammonite.util.Res$Success.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  jupyter.scala.Interp.interpret(\u001b[32mInterp.scala\u001b[39m:\u001b[32m136\u001b[39m)",
      "  jupyter.kernel.interpreter.InterpreterHandler$.$anonfun$execute$3(\u001b[32mInterpreterHandler.scala\u001b[39m:\u001b[32m122\u001b[39m)",
      "  jupyter.kernel.interpreter.InterpreterHandler$.$anonfun$publishing$2(\u001b[32mInterpreterHandler.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  scalaz.concurrent.Task$.Try(\u001b[32mTask.scala\u001b[39m:\u001b[32m457\u001b[39m)",
      "  scalaz.concurrent.Task$.$anonfun$unsafeStart$1(\u001b[32mTask.scala\u001b[39m:\u001b[32m363\u001b[39m)",
      "  scalaz.concurrent.Future$$anon$3.call(\u001b[32mFuture.scala\u001b[39m:\u001b[32m432\u001b[39m)",
      "  scalaz.concurrent.Future$$anon$3.call(\u001b[32mFuture.scala\u001b[39m:\u001b[32m432\u001b[39m)",
      "  java.util.concurrent.FutureTask.run(\u001b[32mFutureTask.java\u001b[39m:\u001b[32m266\u001b[39m)",
      "  java.util.concurrent.ThreadPoolExecutor.runWorker(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m1149\u001b[39m)",
      "  java.util.concurrent.ThreadPoolExecutor$Worker.run(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m624\u001b[39m)",
      "  java.lang.Thread.run(\u001b[32mThread.java\u001b[39m:\u001b[32m748\u001b[39m)"
     ]
    }
   ],
   "source": [
    "import $exclude.`org.slf4j:slf4j-log4j12`, $ivy.`org.slf4j:slf4j-nop:1.7.21` // for cleaner logs\n",
    "import $profile.`hadoop-2.6`\n",
    "import $ivy.`org.apache.spark::spark-sql:2.1.0` // adjust spark version - spark >= 2.0\n",
    "import $ivy.`org.apache.hadoop:hadoop-aws:2.6.4`\n",
    "import $ivy.`org.jupyter-scala::spark:0.4.2` // for JupyterSparkSession (SparkSession aware of the jupyter-scala kernel)\n",
    "\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import jupyter.spark.session._\n",
    "\n",
    "val sparkSession = JupyterSparkSession.builder() // important - call this rather than SparkSession.builder()\n",
    "  .jupyter() // this method must be called straightaway after builder()\n",
    "  // .yarn(\"/etc/hadoop/conf\") // optional, for Spark on YARN - argument is the Hadoop conf directory\n",
    "  // .emr(\"2.6.4\") // on AWS ElasticMapReduce, this adds aws-related to the spark jar list\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small example found around in the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-10T18:25:05.497162Z",
     "start_time": "2017-09-10T16:25:05.275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36moncePerSecond\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mmain\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oncePerSecond(callback: () => Boolean) {\n",
    "while(callback()) {\n",
    "  Thread sleep 1000\n",
    "}\n",
    "}\n",
    "\n",
    "/** Counts down from 0 to 1, approxmimately once per second.\n",
    "*/\n",
    "def main(args: Array[String]) {\n",
    "var count = 10\n",
    "oncePerSecond(() => {println(count); count -= 1; count > 0})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-10T18:25:54.622638Z",
     "start_time": "2017-09-10T16:25:54.186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mz\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m\"Zara\"\u001b[39m, \u001b[32m\"Nuha\"\u001b[39m, \u001b[32m\"Ayan\"\u001b[39m)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var z = Array(\"Zara\", \"Nuha\", \"Ayan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-10T18:26:05.375546Z",
     "start_time": "2017-09-10T16:25:56.138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "main(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala212",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.12.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "47px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
